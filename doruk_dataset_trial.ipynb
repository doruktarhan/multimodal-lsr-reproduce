{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "\n",
    "dense_embs = load_dataset(\"lsr42/mscoco-blip-dense\", data_files={\"img_emb\": \"img_embs.parquet\", \"text_emb\": \"text_embs.parquet\"}, keep_in_memory=True).with_format(\"numpy\")\n",
    "meta_data = json.load(open(hf_hub_download(\n",
    "    repo_id=\"lsr42/mscoco-blip-dense\", repo_type=\"dataset\", filename=\"dataset_meta.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['img_emb', 'text_emb'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_embs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123287, 256)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_embs['img_emb']['emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616767, 256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_embs['text_emb']['emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'emb'],\n",
       "    num_rows: 123287\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_embs['img_emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'dataset'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coco'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data['dataset']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['filepath', 'sentids', 'filename', 'imgid', 'split', 'sentences', 'cocoid'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data['images'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filepath': 'val2014',\n",
       " 'sentids': [681330, 686718, 688839, 693159, 693204],\n",
       " 'filename': 'COCO_val2014_000000522418.jpg',\n",
       " 'imgid': 1,\n",
       " 'split': 'restval',\n",
       " 'sentences': [{'tokens': ['a',\n",
       "    'woman',\n",
       "    'wearing',\n",
       "    'a',\n",
       "    'net',\n",
       "    'on',\n",
       "    'her',\n",
       "    'head',\n",
       "    'cutting',\n",
       "    'a',\n",
       "    'cake'],\n",
       "   'raw': 'A woman wearing a net on her head cutting a cake. ',\n",
       "   'imgid': 1,\n",
       "   'sentid': 681330},\n",
       "  {'tokens': ['a', 'woman', 'cutting', 'a', 'large', 'white', 'sheet', 'cake'],\n",
       "   'raw': 'A woman cutting a large white sheet cake.',\n",
       "   'imgid': 1,\n",
       "   'sentid': 686718},\n",
       "  {'tokens': ['a',\n",
       "    'woman',\n",
       "    'wearing',\n",
       "    'a',\n",
       "    'hair',\n",
       "    'net',\n",
       "    'cutting',\n",
       "    'a',\n",
       "    'large',\n",
       "    'sheet',\n",
       "    'cake'],\n",
       "   'raw': 'A woman wearing a hair net cutting a large sheet cake.',\n",
       "   'imgid': 1,\n",
       "   'sentid': 688839},\n",
       "  {'tokens': ['there',\n",
       "    'is',\n",
       "    'a',\n",
       "    'woman',\n",
       "    'that',\n",
       "    'is',\n",
       "    'cutting',\n",
       "    'a',\n",
       "    'white',\n",
       "    'cake'],\n",
       "   'raw': 'there is a woman that is cutting a white cake',\n",
       "   'imgid': 1,\n",
       "   'sentid': 693159},\n",
       "  {'tokens': ['a',\n",
       "    'woman',\n",
       "    'marking',\n",
       "    'a',\n",
       "    'cake',\n",
       "    'with',\n",
       "    'the',\n",
       "    'back',\n",
       "    'of',\n",
       "    'a',\n",
       "    'chefs',\n",
       "    'knife'],\n",
       "   'raw': \"A woman marking a cake with the back of a chef's knife. \",\n",
       "   'imgid': 1,\n",
       "   'sentid': 693204}],\n",
       " 'cocoid': 522418}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data['images'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embedding shape: (256,)\n",
      "Number of text embeddings found: 5\n",
      "Text embedding shapes: [(256,), (256,), (256,), (256,), (256,)]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text embeddings for fast lookup, normalizing keys to strings\n",
    "text_emb_lookup = {str(item['id']): item['emb'] for item in dense_embs['text_emb']}  # Ensure all keys are strings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embedding shape: (256,)\n",
      "Number of text embeddings found: 5\n",
      "Text embedding shapes: [(256,), (256,), (256,), (256,), (256,)]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve image embedding\n",
    "imgid = meta_data['images'][0]['imgid']\n",
    "example_img_embed = dense_embs['img_emb'][imgid]['emb']\n",
    "\n",
    "# Retrieve text embeddings for the corresponding sentence IDs\n",
    "sentids = meta_data['images'][0]['sentids']\n",
    "text_embeddings = [text_emb_lookup[str(sentid)] for sentid in sentids if str(sentid) in text_emb_lookup]\n",
    "\n",
    "# Output\n",
    "print(f\"Image embedding shape: {example_img_embed.shape}\")\n",
    "print(f\"Number of text embeddings found: {len(text_embeddings)}\")\n",
    "print(f\"Text embedding shapes: {[emb.shape for emb in text_embeddings]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embedding 0 cosine similarity: 0.43064552545547485\n",
      "Text embedding 1 cosine similarity: 0.42722970247268677\n",
      "Text embedding 2 cosine similarity: 0.33973366022109985\n",
      "Text embedding 3 cosine similarity: 0.4240642786026001\n",
      "Text embedding 4 cosine similarity: 0.4385703504085541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\"\"\"\n",
    "for i in range(len(text_embeddings)):\n",
    "    cosine_sim_matrix = cosine_similarity(example_img_embed.reshape(-1,1), text_embeddings[i].reshape(-1,1))\n",
    "    print(f\"Text embedding {i} cosine similarity: {cosine_sim_matrix}\")\n",
    "\n",
    "\"\"\"\n",
    "for i in range(len(text_embeddings)):\n",
    "    pairwise_cosine_sim = np.matmul(example_img_embed, text_embeddings[i].T)\n",
    "    print(f\"Text embedding {i} cosine similarity: {pairwise_cosine_sim}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "path_to_dataset_folder = '/Users/doruktarhan/Desktop/MSCOCO_Dataset' #dataset images folder path\n",
    "# Use glob to find all image files across subdirectories\n",
    "image_files = glob(f'{path_to_dataset_folder}/**/*.jpg', recursive=True)\n",
    "all_image_paths = {os.path.basename(file): file for file in image_files}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load metadata\n",
    "meta_data_path = 'data/dataset_coco.json' #metadata file path\n",
    "with open(meta_data_path, 'r') as f:\n",
    "    meta_data_kaggle = json.load(f)\n",
    "\n",
    "# Display images and metadata for the first 5 instances\n",
    "for idx, metadata_item in enumerate(meta_data_kaggle['images'][:5]):\n",
    "    filename = metadata_item[\"filename\"]  \n",
    "    captions = [sentence[\"raw\"] for sentence in metadata_item[\"sentences\"]]  # Captions list\n",
    "    \n",
    "    # Use the glob-based lookup dictionary to find the image path\n",
    "    image_path = all_image_paths.get(filename)\n",
    "    if not image_path:\n",
    "        print(f\"Image not found: {filename}\")\n",
    "        continue\n",
    "\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Display the metadata and image\n",
    "    print(f\"Metadata for instance {idx + 1}:\")\n",
    "    print(f\"Filename: {filename}\")\n",
    "    print(f\"Captions: {captions}\")\n",
    "\n",
    "    # Plot the image and captions\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Captions: {captions[0]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_kaggle['images'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert metadata to a pandas DataFrame\n",
    "metadata_images = meta_data_kaggle['images']  # Extract the 'images' key\n",
    "df = pd.DataFrame(metadata_images)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Check unique splits and their counts\n",
    "split_counts = df['split'].value_counts()\n",
    "\n",
    "print(\"\\nUnique Splits:\")\n",
    "print(split_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLIP Encoder Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForImageTextRetrieval\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Load the BLIP model and processor\n",
    "model_name = \"Salesforce/blip-itm-large-coco\" #model card for image text matching\n",
    "processor = BlipProcessor.from_pretrained(model_name)\n",
    "model = BlipForImageTextRetrieval.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#load metadata\n",
    "meta_data_path = 'data/dataset_coco.json'\n",
    "with open(meta_data_path, 'r') as f:\n",
    "    meta_data_kaggle = json.load(f)\n",
    "\n",
    "\n",
    "#image path \n",
    "path_to_dataset_folder = '/Users/doruktarhan/Desktop/MSCOCO_Dataset' #dataset images folder path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Define paths\n",
    "path_to_dataset_folder = '/Users/doruktarhan/Desktop/MSCOCO_Dataset' #dataset images folder path\n",
    "# Use glob to find all image files across subdirectories\n",
    "image_files = glob(f'{path_to_dataset_folder}/**/*.jpg', recursive=True)\n",
    "all_image_paths = {os.path.basename(file): file for file in image_files}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load metadata\n",
    "meta_data_path = 'data/dataset_coco.json' #metadata file path\n",
    "with open(meta_data_path, 'r') as f:\n",
    "    meta_data_kaggle = json.load(f)\n",
    "\n",
    "# Display images and metadata for the first 5 instances\n",
    "for idx, metadata_item in enumerate(meta_data_kaggle['images'][:1]):\n",
    "    filename = metadata_item[\"filename\"]  # e.g., '1000092795.jpg'\n",
    "    captions = [sentence[\"raw\"] for sentence in metadata_item[\"sentences\"]]  # Captions list\n",
    "    \n",
    "    # Use the glob-based lookup dictionary to find the image path\n",
    "    image_path = all_image_paths.get(filename)\n",
    "    if not image_path:\n",
    "        print(f\"Image not found: {filename}\")\n",
    "        continue\n",
    "\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Display the metadata and image\n",
    "    print(f\"Metadata for instance {idx + 1}:\")\n",
    "    print(f\"Filename: {filename}\")\n",
    "    print(f\"Captions: {captions}\")\n",
    "\n",
    "    # Plot the image and captions\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Captions: {captions[0]}\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "for caption in captions:\n",
    "    inputs = processor(images=image, text=caption, return_tensors=\"pt\")\n",
    "\n",
    "    # Perform inference\n",
    "    outputs = model(**inputs)\n",
    "    print(f'Caption: {caption}')\n",
    "    print(outputs['itm_score'])\n",
    "    probabilities = softmax(outputs['itm_score'], dim=1)\n",
    "    print(probabilities)\n",
    "    print(outputs['question_embeds'].shape)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = 'Man riding on a motorcycle with blue helmet'\n",
    "inputs = processor(images=image, text=caption, return_tensors=\"pt\")\n",
    "\n",
    "# Perform inference\n",
    "outputs = model(**inputs)\n",
    "print(f'Caption: {caption}')\n",
    "print(f\"Output tensor itm matching score: {outputs['itm_score']}\")\n",
    "probabilities = softmax(outputs['itm_score'], dim=1)\n",
    "print(f\"Probabilities after softmax: {probabilities}\")\n",
    "\n",
    "print(f\"Question embedding shape: {outputs['question_embeds'].shape}\")\n",
    "print(f\"Image embedding shape: {outputs['last_hidden_state'].shape}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "\n",
    "proj_text_embedding = normalize(model.text_proj(outputs.question_embeds[:,0,:]))\n",
    "proj_image_embedding = normalize(model.vision_proj(outputs.last_hidden_state[:,0,:]))\n",
    "\n",
    "\n",
    "print(f\"Image projection shape: {proj_image_embedding.shape}\")\n",
    "print(f\"Text projection shape: {proj_text_embedding.shape}\")\n",
    "\n",
    "# Compute pairwise cosine similarity (matrix)\n",
    "pairwise_cosine_sim = torch.matmul(proj_image_embedding, proj_text_embedding.T)\n",
    "\n",
    "print(f\"Pairwise cosine similarity:\\n{pairwise_cosine_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities for each image-text pair:\n",
      "Pair 1: 0.4717683494091034\n",
      "Pair 2: 0.4680973291397095\n",
      "Pair 3: 0.4207531213760376\n",
      "Pair 4: 0.5063284635543823\n",
      "Pair 5: 0.4703652560710907\n",
      "Pair 6: 0.4047545790672302\n",
      "Pair 7: 0.46468424797058105\n",
      "Pair 8: 0.46485379338264465\n",
      "Pair 9: 0.4473761022090912\n",
      "Pair 10: 0.5034165978431702\n",
      "Pair 11: 0.42352989315986633\n",
      "Pair 12: 0.5207198262214661\n",
      "Pair 13: 0.4432687759399414\n",
      "Pair 14: 0.44502633810043335\n",
      "Pair 15: 0.5233748555183411\n",
      "Pair 16: 0.44414687156677246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/056tygps4hv_9gn5wdt55xwh0000gn/T/ipykernel_78812/1152185754.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(file_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the saved embeddings\n",
    "file_path = \"test_embeddings/blip_test/test_batch.pt\"\n",
    "embeddings = torch.load(file_path)\n",
    "\n",
    "# Extract the embeddings\n",
    "image_embeds = embeddings[\"image_embeds\"]  # (batch_size, embedding_dim)\n",
    "text_embeds = embeddings[\"text_embeds\"]    # (batch_size, embedding_dim)\n",
    "\n",
    "# Normalize the embeddings\n",
    "image_embeds = torch.nn.functional.normalize(image_embeds, p=2, dim=1)  # Normalize along embedding dimension\n",
    "text_embeds = torch.nn.functional.normalize(text_embeds, p=2, dim=1)\n",
    "\n",
    "# Compute pairwise cosine similarity for each image-text pair\n",
    "cosine_similarities = torch.sum(image_embeds * text_embeds, dim=1)\n",
    "\n",
    "# Print the results\n",
    "print(\"Cosine similarities for each image-text pair:\")\n",
    "for i, sim in enumerate(cosine_similarities):\n",
    "    print(f\"Pair {i+1}: {sim.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0 and Text 0 Cosine Similarity: 0.4717683795442903\n",
      "Image 1 and Text 1 Cosine Similarity: 0.4680973760820966\n",
      "Image 2 and Text 2 Cosine Similarity: 0.42075334066719833\n",
      "Image 3 and Text 3 Cosine Similarity: 0.5063282873348682\n",
      "Image 4 and Text 4 Cosine Similarity: 0.47036502239183337\n",
      "Image 5 and Text 5 Cosine Similarity: 0.4047548874558168\n",
      "Image 6 and Text 6 Cosine Similarity: 0.46468458497358284\n",
      "Image 7 and Text 7 Cosine Similarity: 0.4648540968885047\n",
      "Image 8 and Text 8 Cosine Similarity: 0.44737641313792575\n",
      "Image 9 and Text 9 Cosine Similarity: 0.5034165912001807\n",
      "Image 10 and Text 10 Cosine Similarity: 0.42353017969376117\n",
      "Image 11 and Text 11 Cosine Similarity: 0.5207200707088676\n",
      "Image 12 and Text 12 Cosine Similarity: 0.44326884858981475\n",
      "Image 13 and Text 13 Cosine Similarity: 0.4450265627638724\n",
      "Image 14 and Text 14 Cosine Similarity: 0.5233751381856252\n",
      "Image 15 and Text 15 Cosine Similarity: 0.44414677803119235\n",
      "Image 16 and Text 16 Cosine Similarity: 0.4793473543447772\n",
      "Image 17 and Text 17 Cosine Similarity: 0.4356533611413014\n",
      "Image 18 and Text 18 Cosine Similarity: 0.4309101163097263\n",
      "Image 19 and Text 19 Cosine Similarity: 0.5015820862927842\n",
      "Image 20 and Text 20 Cosine Similarity: 0.522236630647077\n",
      "Image 21 and Text 21 Cosine Similarity: 0.41738694455962166\n",
      "Image 22 and Text 22 Cosine Similarity: 0.4072800725170207\n",
      "Image 23 and Text 23 Cosine Similarity: 0.4714113535882996\n",
      "Image 24 and Text 24 Cosine Similarity: 0.4297200493183641\n",
      "Image 25 and Text 25 Cosine Similarity: 0.39379195782631937\n",
      "Image 26 and Text 26 Cosine Similarity: 0.3977992706057807\n",
      "Image 27 and Text 27 Cosine Similarity: 0.4120485521408655\n",
      "Image 28 and Text 28 Cosine Similarity: 0.4040773417332845\n",
      "Image 29 and Text 29 Cosine Similarity: 0.512074675459568\n",
      "Image 30 and Text 30 Cosine Similarity: 0.4495464530132644\n",
      "Image 31 and Text 31 Cosine Similarity: 0.49674606532769705\n",
      "Image 32 and Text 32 Cosine Similarity: 0.5163198057323475\n",
      "Image 33 and Text 33 Cosine Similarity: 0.4340824370620952\n",
      "Image 34 and Text 34 Cosine Similarity: 0.520419783119026\n",
      "Image 35 and Text 35 Cosine Similarity: 0.4369203066860155\n",
      "Image 36 and Text 36 Cosine Similarity: 0.43218872202627207\n",
      "Image 37 and Text 37 Cosine Similarity: 0.4226983376084573\n",
      "Image 38 and Text 38 Cosine Similarity: 0.4687447064453166\n",
      "Image 39 and Text 39 Cosine Similarity: 0.4347258419547227\n",
      "Image 40 and Text 40 Cosine Similarity: 0.47105595154716096\n",
      "Image 41 and Text 41 Cosine Similarity: 0.4554923397258447\n",
      "Image 42 and Text 42 Cosine Similarity: 0.4500428471712859\n",
      "Image 43 and Text 43 Cosine Similarity: 0.49244916889180657\n",
      "Image 44 and Text 44 Cosine Similarity: 0.4187649746305794\n",
      "Image 45 and Text 45 Cosine Similarity: 0.49897355335794874\n",
      "Image 46 and Text 46 Cosine Similarity: 0.4672987381112515\n",
      "Image 47 and Text 47 Cosine Similarity: 0.4622806989385365\n",
      "Image 48 and Text 48 Cosine Similarity: 0.45395756221846867\n",
      "Image 49 and Text 49 Cosine Similarity: 0.4781165935815349\n",
      "Image 50 and Text 50 Cosine Similarity: 0.4813660975556993\n",
      "Image 51 and Text 51 Cosine Similarity: 0.47644284313102486\n",
      "Image 52 and Text 52 Cosine Similarity: 0.481094609067901\n",
      "Image 53 and Text 53 Cosine Similarity: 0.488807815516479\n",
      "Image 54 and Text 54 Cosine Similarity: 0.5185967471728302\n",
      "Image 55 and Text 55 Cosine Similarity: 0.4957575141045178\n",
      "Image 56 and Text 56 Cosine Similarity: 0.4765762356946488\n",
      "Image 57 and Text 57 Cosine Similarity: 0.47940218457556427\n",
      "Image 58 and Text 58 Cosine Similarity: 0.5219470112723746\n",
      "Image 59 and Text 59 Cosine Similarity: 0.46725753999816527\n",
      "Image 60 and Text 60 Cosine Similarity: 0.43412668794948733\n",
      "Image 61 and Text 61 Cosine Similarity: 0.4257113893892388\n",
      "Image 62 and Text 62 Cosine Similarity: 0.4665562091906297\n",
      "Image 63 and Text 63 Cosine Similarity: 0.43419618911430435\n",
      "Image 64 and Text 64 Cosine Similarity: 0.4451885442259701\n",
      "Image 65 and Text 65 Cosine Similarity: 0.4224255224561421\n",
      "Image 66 and Text 66 Cosine Similarity: 0.47331626730414944\n",
      "Image 67 and Text 67 Cosine Similarity: 0.4538309963009627\n",
      "Image 68 and Text 68 Cosine Similarity: 0.4505601214318069\n",
      "Image 69 and Text 69 Cosine Similarity: 0.4728560683937763\n",
      "Image 70 and Text 70 Cosine Similarity: 0.5431993951950531\n",
      "Image 71 and Text 71 Cosine Similarity: 0.507995686890035\n",
      "Image 72 and Text 72 Cosine Similarity: 0.5450734354028387\n",
      "Image 73 and Text 73 Cosine Similarity: 0.5459564534923542\n",
      "Image 74 and Text 74 Cosine Similarity: 0.5388431898374271\n",
      "Image 75 and Text 75 Cosine Similarity: 0.47124689471643244\n",
      "Image 76 and Text 76 Cosine Similarity: 0.5230431411086346\n",
      "Image 77 and Text 77 Cosine Similarity: 0.5309734189867116\n",
      "Image 78 and Text 78 Cosine Similarity: 0.5012414896120077\n",
      "Image 79 and Text 79 Cosine Similarity: 0.47551644955537403\n",
      "Image 80 and Text 80 Cosine Similarity: 0.5175224500558723\n",
      "Image 81 and Text 81 Cosine Similarity: 0.5142306772043712\n",
      "Image 82 and Text 82 Cosine Similarity: 0.45330707089175953\n",
      "Image 83 and Text 83 Cosine Similarity: 0.5033511758918365\n",
      "Image 84 and Text 84 Cosine Similarity: 0.49619976968448887\n",
      "Image 85 and Text 85 Cosine Similarity: 0.4589004519563871\n",
      "Image 86 and Text 86 Cosine Similarity: 0.46610040277325177\n",
      "Image 87 and Text 87 Cosine Similarity: 0.45516521310613284\n",
      "Image 88 and Text 88 Cosine Similarity: 0.47733900870516066\n",
      "Image 89 and Text 89 Cosine Similarity: 0.47528432035708823\n",
      "Image 90 and Text 90 Cosine Similarity: 0.4297676291943938\n",
      "Image 91 and Text 91 Cosine Similarity: 0.5403130140867394\n",
      "Image 92 and Text 92 Cosine Similarity: 0.505669040377864\n",
      "Image 93 and Text 93 Cosine Similarity: 0.5023413060543803\n",
      "Image 94 and Text 94 Cosine Similarity: 0.4371590555658064\n",
      "Image 95 and Text 95 Cosine Similarity: 0.4509987620661283\n",
      "Image 96 and Text 96 Cosine Similarity: 0.45593473419320185\n",
      "Image 97 and Text 97 Cosine Similarity: 0.47029442695088647\n",
      "Image 98 and Text 98 Cosine Similarity: 0.43281576643597586\n",
      "Image 99 and Text 99 Cosine Similarity: 0.457135048533975\n",
      "Image 100 and Text 100 Cosine Similarity: 0.49209832105707885\n",
      "Image 101 and Text 101 Cosine Similarity: 0.47148669988232805\n",
      "Image 102 and Text 102 Cosine Similarity: 0.4338586508103011\n",
      "Image 103 and Text 103 Cosine Similarity: 0.5130952648779856\n",
      "Image 104 and Text 104 Cosine Similarity: 0.47813462020731085\n",
      "Image 105 and Text 105 Cosine Similarity: 0.4974450514542333\n",
      "Image 106 and Text 106 Cosine Similarity: 0.4024846093576741\n",
      "Image 107 and Text 107 Cosine Similarity: 0.4227723085420984\n",
      "Image 108 and Text 108 Cosine Similarity: 0.42793596580562576\n",
      "Image 109 and Text 109 Cosine Similarity: 0.49512268601788806\n",
      "Image 110 and Text 110 Cosine Similarity: 0.49331871809429584\n",
      "Image 111 and Text 111 Cosine Similarity: 0.48561653422193046\n",
      "Image 112 and Text 112 Cosine Similarity: 0.47118339524564323\n",
      "Image 113 and Text 113 Cosine Similarity: 0.47184867726506347\n",
      "Image 114 and Text 114 Cosine Similarity: 0.499059329871203\n",
      "Image 115 and Text 115 Cosine Similarity: 0.283241038880862\n",
      "Image 116 and Text 116 Cosine Similarity: 0.5019251358381522\n",
      "Image 117 and Text 117 Cosine Similarity: 0.44520312133244444\n",
      "Image 118 and Text 118 Cosine Similarity: 0.4166380198524858\n",
      "Image 119 and Text 119 Cosine Similarity: 0.49646535307263684\n",
      "Image 120 and Text 120 Cosine Similarity: 0.41346026547776155\n",
      "Image 121 and Text 121 Cosine Similarity: 0.4826408072626763\n",
      "Image 122 and Text 122 Cosine Similarity: 0.47075997681255255\n",
      "Image 123 and Text 123 Cosine Similarity: 0.4513778673387251\n",
      "Image 124 and Text 124 Cosine Similarity: 0.45853558821539686\n",
      "Image 125 and Text 125 Cosine Similarity: 0.471814147046824\n",
      "Image 126 and Text 126 Cosine Similarity: 0.45564073306808\n",
      "Image 127 and Text 127 Cosine Similarity: 0.4860088805598235\n",
      "Image 128 and Text 128 Cosine Similarity: 0.5121921893136308\n",
      "Image 129 and Text 129 Cosine Similarity: 0.5263180440238371\n",
      "Image 130 and Text 130 Cosine Similarity: 0.47501575875578766\n",
      "Image 131 and Text 131 Cosine Similarity: 0.4527954936342195\n",
      "Image 132 and Text 132 Cosine Similarity: 0.47323102050587634\n",
      "Image 133 and Text 133 Cosine Similarity: 0.4523625785855691\n",
      "Image 134 and Text 134 Cosine Similarity: 0.4492053853455455\n",
      "Image 135 and Text 135 Cosine Similarity: 0.4778067159776884\n",
      "Image 136 and Text 136 Cosine Similarity: 0.5012609965276231\n",
      "Image 137 and Text 137 Cosine Similarity: 0.49834549832097985\n",
      "Image 138 and Text 138 Cosine Similarity: 0.49516094435151203\n",
      "Image 139 and Text 139 Cosine Similarity: 0.49580294548554055\n",
      "Image 140 and Text 140 Cosine Similarity: 0.4587806365709981\n",
      "Image 141 and Text 141 Cosine Similarity: 0.4737371131334824\n",
      "Image 142 and Text 142 Cosine Similarity: 0.4353498624453112\n",
      "Image 143 and Text 143 Cosine Similarity: 0.4359553521993467\n",
      "Image 144 and Text 144 Cosine Similarity: 0.4933806825701136\n",
      "Image 145 and Text 145 Cosine Similarity: 0.5019216123212253\n",
      "Image 146 and Text 146 Cosine Similarity: 0.42697570779185556\n",
      "Image 147 and Text 147 Cosine Similarity: 0.5078620231908381\n",
      "Image 148 and Text 148 Cosine Similarity: 0.49362158233144915\n",
      "Image 149 and Text 149 Cosine Similarity: 0.4794913849583112\n",
      "Image 150 and Text 150 Cosine Similarity: 0.5574289312684023\n",
      "Image 151 and Text 151 Cosine Similarity: 0.5364908051047474\n",
      "Image 152 and Text 152 Cosine Similarity: 0.5168164250785253\n",
      "Image 153 and Text 153 Cosine Similarity: 0.5439371345659076\n",
      "Image 154 and Text 154 Cosine Similarity: 0.4661129819435794\n",
      "Image 155 and Text 155 Cosine Similarity: 0.4326960992630733\n",
      "Image 156 and Text 156 Cosine Similarity: 0.4425901629965591\n",
      "Image 157 and Text 157 Cosine Similarity: 0.44676743437534\n",
      "Image 158 and Text 158 Cosine Similarity: 0.40030347450129633\n",
      "Image 159 and Text 159 Cosine Similarity: 0.47085222896999046\n",
      "Image 160 and Text 160 Cosine Similarity: 0.477623811392103\n",
      "Image 161 and Text 161 Cosine Similarity: 0.5043384793169301\n",
      "Image 162 and Text 162 Cosine Similarity: 0.4874079021665168\n",
      "Image 163 and Text 163 Cosine Similarity: 0.5234135729742188\n",
      "Image 164 and Text 164 Cosine Similarity: 0.5071363434711476\n",
      "Image 165 and Text 165 Cosine Similarity: 0.4873091883666501\n",
      "Image 166 and Text 166 Cosine Similarity: 0.4377819416538945\n",
      "Image 167 and Text 167 Cosine Similarity: 0.408658680344759\n",
      "Image 168 and Text 168 Cosine Similarity: 0.5089854203472264\n",
      "Image 169 and Text 169 Cosine Similarity: 0.4015088736976434\n",
      "Image 170 and Text 170 Cosine Similarity: 0.5089613887404669\n",
      "Image 171 and Text 171 Cosine Similarity: 0.4804484443033548\n",
      "Image 172 and Text 172 Cosine Similarity: 0.5223213056805037\n",
      "Image 173 and Text 173 Cosine Similarity: 0.453621297064053\n",
      "Image 174 and Text 174 Cosine Similarity: 0.4850428358584832\n",
      "Image 175 and Text 175 Cosine Similarity: 0.5323547407130825\n",
      "Image 176 and Text 176 Cosine Similarity: 0.542765863074712\n",
      "Image 177 and Text 177 Cosine Similarity: 0.41948725762108224\n",
      "Image 178 and Text 178 Cosine Similarity: 0.5006268828457242\n",
      "Image 179 and Text 179 Cosine Similarity: 0.5413537312842855\n",
      "Image 180 and Text 180 Cosine Similarity: 0.5093174094739468\n",
      "Image 181 and Text 181 Cosine Similarity: 0.47936708217859464\n",
      "Image 182 and Text 182 Cosine Similarity: 0.4961100373471933\n",
      "Image 183 and Text 183 Cosine Similarity: 0.4950072892820398\n",
      "Image 184 and Text 184 Cosine Similarity: 0.48258085307443327\n",
      "Image 185 and Text 185 Cosine Similarity: 0.43945006433758943\n",
      "Image 186 and Text 186 Cosine Similarity: 0.43756192664567584\n",
      "Image 187 and Text 187 Cosine Similarity: 0.43384657515421254\n",
      "Image 188 and Text 188 Cosine Similarity: 0.4675990425297318\n",
      "Image 189 and Text 189 Cosine Similarity: 0.43272250776887733\n",
      "Image 190 and Text 190 Cosine Similarity: 0.48812613425723483\n",
      "Image 191 and Text 191 Cosine Similarity: 0.5314234203819806\n",
      "Image 192 and Text 192 Cosine Similarity: 0.5352610755827345\n",
      "Image 193 and Text 193 Cosine Similarity: 0.5318502187704242\n",
      "Image 194 and Text 194 Cosine Similarity: 0.4861859953112195\n",
      "Image 195 and Text 195 Cosine Similarity: 0.4231572245244358\n",
      "Image 196 and Text 196 Cosine Similarity: 0.45633451035022565\n",
      "Image 197 and Text 197 Cosine Similarity: 0.4465765291515205\n",
      "Image 198 and Text 198 Cosine Similarity: 0.44209110673349267\n",
      "Image 199 and Text 199 Cosine Similarity: 0.4801761841621451\n",
      "Image 200 and Text 200 Cosine Similarity: 0.48312434148371053\n",
      "Image 201 and Text 201 Cosine Similarity: 0.4307189117701642\n",
      "Image 202 and Text 202 Cosine Similarity: 0.4160274208473159\n",
      "Image 203 and Text 203 Cosine Similarity: 0.5117960031541694\n",
      "Image 204 and Text 204 Cosine Similarity: 0.45237655815489486\n",
      "Image 205 and Text 205 Cosine Similarity: 0.45803642854679766\n",
      "Image 206 and Text 206 Cosine Similarity: 0.344790534976504\n",
      "Image 207 and Text 207 Cosine Similarity: 0.38563499627956643\n",
      "Image 208 and Text 208 Cosine Similarity: 0.4755713984068876\n",
      "Image 209 and Text 209 Cosine Similarity: 0.4366986885562263\n",
      "Image 210 and Text 210 Cosine Similarity: 0.5104442651718836\n",
      "Image 211 and Text 211 Cosine Similarity: 0.4770983846919276\n",
      "Image 212 and Text 212 Cosine Similarity: 0.44974795946142915\n",
      "Image 213 and Text 213 Cosine Similarity: 0.5007621723535542\n",
      "Image 214 and Text 214 Cosine Similarity: 0.4395057450489646\n",
      "Image 215 and Text 215 Cosine Similarity: 0.46765435630260677\n",
      "Image 216 and Text 216 Cosine Similarity: 0.4014150779867993\n",
      "Image 217 and Text 217 Cosine Similarity: 0.4758238830781223\n",
      "Image 218 and Text 218 Cosine Similarity: 0.4338059037773851\n",
      "Image 219 and Text 219 Cosine Similarity: 0.46876981402290574\n",
      "Image 220 and Text 220 Cosine Similarity: 0.5176667944053769\n",
      "Image 221 and Text 221 Cosine Similarity: 0.4092217380615784\n",
      "Image 222 and Text 222 Cosine Similarity: 0.4935909911505303\n",
      "Image 223 and Text 223 Cosine Similarity: 0.4429653809350834\n",
      "Image 224 and Text 224 Cosine Similarity: 0.5323274946393642\n",
      "Image 225 and Text 225 Cosine Similarity: 0.4780777037548473\n",
      "Image 226 and Text 226 Cosine Similarity: 0.473818872230116\n",
      "Image 227 and Text 227 Cosine Similarity: 0.4838714240744468\n",
      "Image 228 and Text 228 Cosine Similarity: 0.4813209040680712\n",
      "Image 229 and Text 229 Cosine Similarity: 0.4491580774679702\n",
      "Image 230 and Text 230 Cosine Similarity: 0.5058601754358878\n",
      "Image 231 and Text 231 Cosine Similarity: 0.55458908242409\n",
      "Image 232 and Text 232 Cosine Similarity: 0.476501335114572\n",
      "Image 233 and Text 233 Cosine Similarity: 0.5348278660600667\n",
      "Image 234 and Text 234 Cosine Similarity: 0.5478910158917158\n",
      "Image 235 and Text 235 Cosine Similarity: 0.4427033735705194\n",
      "Image 236 and Text 236 Cosine Similarity: 0.3999459483528107\n",
      "Image 237 and Text 237 Cosine Similarity: 0.4886699987502707\n",
      "Image 238 and Text 238 Cosine Similarity: 0.5394959502979996\n",
      "Image 239 and Text 239 Cosine Similarity: 0.4979606949752858\n",
      "Image 240 and Text 240 Cosine Similarity: 0.534466979437884\n",
      "Image 241 and Text 241 Cosine Similarity: 0.5274242331274707\n",
      "Image 242 and Text 242 Cosine Similarity: 0.4918750745204206\n",
      "Image 243 and Text 243 Cosine Similarity: 0.45376596096359617\n",
      "Image 244 and Text 244 Cosine Similarity: 0.4849585571370906\n",
      "Image 245 and Text 245 Cosine Similarity: 0.5048094732869354\n",
      "Image 246 and Text 246 Cosine Similarity: 0.48582095880711196\n",
      "Image 247 and Text 247 Cosine Similarity: 0.5027884832454119\n",
      "Image 248 and Text 248 Cosine Similarity: 0.4600636883371654\n",
      "Image 249 and Text 249 Cosine Similarity: 0.4803435830328987\n",
      "Image 250 and Text 250 Cosine Similarity: 0.4589423783366235\n",
      "Image 251 and Text 251 Cosine Similarity: 0.45411197026144545\n",
      "Image 252 and Text 252 Cosine Similarity: 0.4842972784280946\n",
      "Image 253 and Text 253 Cosine Similarity: 0.4417939824450732\n",
      "Image 254 and Text 254 Cosine Similarity: 0.39540835514694805\n",
      "Image 255 and Text 255 Cosine Similarity: 0.435257799332814\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Paths to the Parquet files\n",
    "img_embs_path = \"blip_trial_embeds/img_embs.parquet\"\n",
    "text_embs_path = \"blip_trial_embeds/text_embs.parquet\"\n",
    "\n",
    "# Load Parquet files\n",
    "img_embs_df = pd.read_parquet(img_embs_path)\n",
    "text_embs_df = pd.read_parquet(text_embs_path)\n",
    "\n",
    "# Ensure one-to-one correspondence\n",
    "assert len(img_embs_df) == len(text_embs_df), \"Mismatch in image and text embeddings!\"\n",
    "\n",
    "# Extract embeddings and convert them to tensors\n",
    "img_embs = torch.tensor(np.vstack(img_embs_df['embedding'].values))\n",
    "text_embs = torch.tensor(np.vstack(text_embs_df['embedding'].values))\n",
    "\n",
    "# Normalize embeddings for cosine similarity (optional, depends on the model output)\n",
    "img_embs_normalized = torch.nn.functional.normalize(img_embs, dim=1)\n",
    "text_embs_normalized = torch.nn.functional.normalize(text_embs, dim=1)\n",
    "\n",
    "# Compute pairwise cosine similarity using matrix multiplication\n",
    "cosine_similarities = torch.matmul(img_embs_normalized, text_embs_normalized.T)\n",
    "\n",
    "# Extract diagonal elements for one-to-one correspondence cosine similarities\n",
    "one_to_one_cosine_similarities = cosine_similarities.diag()\n",
    "\n",
    "# Print the cosine similarities\n",
    "for idx, sim in enumerate(one_to_one_cosine_similarities):\n",
    "    print(f\"Image {idx} and Text {idx} Cosine Similarity: {sim.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
