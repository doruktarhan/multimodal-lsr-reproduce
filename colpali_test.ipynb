{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.07s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from colpali_engine.models import ColQwen2, ColQwen2Processor\n",
    "\n",
    "model = ColQwen2.from_pretrained(\n",
    "        \"vidore/colqwen2-v1.0\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=None,  # or \"mps\" if on Apple Silicon\n",
    "    ).eval()\n",
    "processor = ColQwen2Processor.from_pretrained(\"vidore/colqwen2-v1.0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing metadata: 100%|██████████| 123287/123287 [00:00<00:00, 313151.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image-caption pairs extracted: 160\n",
      "Example pair: (42475, 40576, '/Users/doruktarhan/Desktop/MSCOCO_trial_images_small/train2014/COCO_train2014_000000000089.jpg', 'An oven with a stove on top of it in a kitchen.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Blip2ForImageTextRetrieval\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 1: Define the paths\n",
    "metadata_path = \"meta_data_old_without_filtering/dataset_coco.json\"  # Path to the metadata JSON file\n",
    "image_dir = \"/Users/doruktarhan/Desktop/MSCOCO_trial_images_small/train2014\"   # Path to the directory containing images\n",
    "\n",
    "# Step 2: Load the metadata\n",
    "with open(metadata_path, \"r\") as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "# Step 3: Extract image-caption pairs\n",
    "image_caption_pairs = []\n",
    "\n",
    "for image_data in tqdm(metadata[\"images\"], desc=\"Processing metadata\"):\n",
    "    image_id = image_data[\"imgid\"]\n",
    "    filename = image_data[\"filename\"]\n",
    "    filepath = os.path.join(image_dir, filename)\n",
    "\n",
    "    # Verify if the image file exists\n",
    "    if os.path.exists(filepath):\n",
    "        for sentence_data in image_data[\"sentences\"]:\n",
    "            caption_id = sentence_data[\"sentid\"]\n",
    "            caption = sentence_data[\"raw\"]\n",
    "            image_caption_pairs.append((image_id, caption_id, filepath, caption))\n",
    "\n",
    "\n",
    "print(f\"Total image-caption pairs extracted: {len(image_caption_pairs)}\")\n",
    "print(\"Example pair:\", image_caption_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing image-caption pairs: 100%|██████████| 160/160 [34:33<00:00, 12.96s/it] \n"
     ]
    }
   ],
   "source": [
    "# Step 5: Process the images and captions\n",
    "processed_data = []\n",
    "\n",
    "for image_id, caption_id, filepath, caption in tqdm(image_caption_pairs, desc=\"Processing image-caption pairs\"):\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(filepath).convert(\"RGB\")\n",
    "    \n",
    "    # Preprocess the image\n",
    "    batch_images = processor.process_images(images=[image])\n",
    "    batch_captions = processor.process_queries(queries=[caption])\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        image_embeds = model(**batch_images)\n",
    "        text_embeds = model(**batch_captions)\n",
    "    \n",
    "    # Save the embeddings\n",
    "    processed_data.append({\n",
    "        \"image_id\": image_id,\n",
    "        \"caption_id\": caption_id,\n",
    "        \"image_filepath\": filepath,\n",
    "        \"caption\": caption,\n",
    "        \"image_embeds\": image_embeds,\n",
    "        \"text_embeds\": text_embeds\n",
    "    })\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 402, 128]), torch.Size([1, 25, 128]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0]['image_embeds'].shape, processed_data[0]['text_embeds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed pairs: 160\n",
      "Example Processed Pair Outputs:\n",
      "Image ID: 42475\n",
      "Caption ID: 40576\n",
      "Caption: An oven with a stove on top of it in a kitchen.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Total processed pairs: {len(processed_data)}\")\n",
    "\n",
    "# Step 6: Inspect results\n",
    "print(\"Example Processed Pair Outputs:\")\n",
    "example = processed_data[0]\n",
    "print(\"Image ID:\", example[\"image_id\"])\n",
    "print(\"Caption ID:\", example[\"caption_id\"])\n",
    "print(\"Caption:\", example[\"caption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n",
      "Max Similarity: 0.99609375, Max Index: 0\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import normalize,cosine_similarity\n",
    "\n",
    "# Process the embeddings\n",
    "for data in processed_data:\n",
    "\n",
    "    image_embeds = normalize(data[\"image_embeds\"][:,0,:], p=2, dim=-1)\n",
    "    text_embeds = normalize(data[\"text_embeds\"][:,0,:], p=2, dim=-1)\n",
    "\n",
    "    # Compute cosine similarity for each of the 32 image embeddings\n",
    "    similarities = cosine_similarity(image_embeds.squeeze(0), text_embeds.squeeze(0), dim=-1)  # [32]\n",
    "    \n",
    "    # Get the maximum similarity score and the corresponding index\n",
    "    max_similarity, max_index = similarities.max(dim=0)\n",
    "    \n",
    "    # Save the result back to the data for inspection\n",
    "    data[\"max_similarity\"] = max_similarity.item()\n",
    "    data[\"max_index\"] = max_index.item()\n",
    "\n",
    "# Inspect results\n",
    "for data in processed_data:\n",
    "    print(f\"Max Similarity: {data['max_similarity']}, Max Index: {data['max_index']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colqwen_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
